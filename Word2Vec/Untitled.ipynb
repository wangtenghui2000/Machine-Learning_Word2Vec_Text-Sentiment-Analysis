{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg = pd.read_excel('neg.xls',header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = pd.read_excel('pos.xls',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/3c/4y6515r52bg3xm59_qswvrrh0000gn/T/jieba.cache\n",
      "Loading model cost 0.419 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "neg['words'] = neg[0].apply(lambda x: jieba.lcut(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos['words'] = pos[0].apply(lambda x: jieba.lcut(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.concatenate((pos['words'],neg['words']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.concatenate((np.ones(len(pos)),np.zeros(len(neg))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = Word2Vec(size=300,min_count=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v.build_vocab(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8131792, 11948800)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.train(x,total_examples=w2v.corpus_count,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v.save(u'w2v_model.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_vec(words):\n",
    "    vec = np.zeros(300).reshape((1,300))\n",
    "    for word in words:\n",
    "        try:\n",
    "            vec += w2v.wv[word].reshape((1,300))\n",
    "        except KeyError:\n",
    "            continue\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vec = np.concatenate([total_vec(words) for words in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(kernel='rbf',verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['svm_model.pkl']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_vec,y)\n",
    "joblib.dump(model,'svm_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load('svm_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_vec(words):\n",
    "    w2v = Word2Vec.load('w2v_model.model')\n",
    "    vec = np.zeros(300).reshape((1,300))\n",
    "    for word in words:\n",
    "        try:\n",
    "            vec += w2v.wv[word].reshape((1,300))\n",
    "        except KeyError:\n",
    "            continue\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_predict():\n",
    "    df = pd.read_csv(\"test.csv\")\n",
    "    \n",
    "    model = joblib.load('svm_model.pkl')\n",
    "    comment_sentiment = []\n",
    "    sum_counter = 0;\n",
    "    right = 0;\n",
    "    wrong = 0;\n",
    "    for string in df['内容']:\n",
    "        words = jieba.lcut(str(string))\n",
    "        words_vec = total_vec(words)\n",
    "        result = model.predict(words_vec)\n",
    "        comment_sentiment.append('积极' if int(result[0]) else '消极')\n",
    "        \n",
    "        if sum_counter < 1500:\n",
    "            if int(result[0]) == 1:\n",
    "                right += 1\n",
    "            else:\n",
    "                wrong += 1\n",
    "        else:\n",
    "            if int(result[0]) == 0:\n",
    "                right += 1\n",
    "            else:\n",
    "                wrong += 1\n",
    "        sum_counter += 1\n",
    "    \n",
    "    result = right / sum_counter\n",
    "    print(\"判断正确：\", right)\n",
    "    print(\"判断错误：\", wrong)\n",
    "    print(\"准确率：\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "判断正确： 2599\n",
      "判断错误： 401\n",
      "准确率： 0.8663333333333333\n"
     ]
    }
   ],
   "source": [
    "svm_predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
